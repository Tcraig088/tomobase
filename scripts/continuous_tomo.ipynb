{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Tomography\n",
    "\n",
    "This Juypter Notebook is a tutorial for generating simulated data for the publication: ..................\n",
    "\n",
    "Table of Contents\n",
    "[Setup](#21-manage-imports)\n",
    "[Tests](#tests)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Manage Imports \n",
    "This section is to manage imports for libraries necessary to run the code. Data will be simulated from the Nanocage 3D volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astra\n",
    "print(astra.use_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomobase\n",
    "import numpy as np\n",
    "import tomobase.phantoms\n",
    "import tomobase.processes\n",
    "import tomobase.processes.alignments\n",
    "import tomobase.tiltschemes\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "vol = tomobase.phantoms.nanocage()\n",
    "pd.set_option('display.max_rows', None)\n",
    "import astra\n",
    "print(astra.use_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomobase\n",
    "import numpy as np\n",
    "import tomobase.phantoms\n",
    "import tomobase.processes.alignments\n",
    "import tomobase.tiltschemes\n",
    "import mrcfile\n",
    "\n",
    "\n",
    "vol =  tomobase.phantoms.nanocage()\n",
    "scheme = tomobase.tiltschemes.Binary(-64,64, 8)\n",
    "angles = np.array([scheme.get_angle() for i in range(65)])\n",
    "sino = tomobase.processes.project(vol, angles)\n",
    "tomobase.processes.alignments.poisson_noise(sino, 10)\n",
    "sino.data = np.transpose(sino.data,(2,1,0))\n",
    "sino.to_file('sino.mrc')\n",
    "\n",
    "#meta={'angles': self.angles, 'times': self.times}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomobase\n",
    "import copy\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "\n",
    "\n",
    "vol =  tomobase.phantoms.nanocage()\n",
    "schemes = get_required_schemes()\n",
    "\n",
    "for scheme in schemes:\n",
    "    angles = np.array([scheme.get_angle() for i in range(65)])\n",
    "    sino = tomobase.processes.project(vol, angles)\n",
    "    rec = tomobase.processes.reconstruct_weighted_sirt(sino, 100, weighted=True)\n",
    "    rmse = np.sqrt(np.mean((vol.data - rec.data)**2))\n",
    "    ssim = structural_similarity(vol.data, rec.data, data_range=1.0)\n",
    "    print('Incremental', rmse, ssim)\n",
    "\n",
    "\n",
    "rec.to_file('inc.rec')\n",
    "print('Done')\n",
    "sinos = [sino_inc, sino_bin, sino_grs]\n",
    "for sino in sinos:\n",
    "    noises = [0, 0.1, 1.0, 10.0]\n",
    "    for noise in noises:\n",
    "        if noise == 0: \n",
    "            sino_noisy = sino\n",
    "        else:\n",
    "            sino_noisy =  tomobase.processes.alignments.poisson_noise(sino_noisy, noise, inplace=False)\n",
    "        rec = tomobase.processes.reconstruct_weighted_sirt(sino_noisy, 100, True, True)\n",
    "        vol2 = copy.deepcopy(vol)\n",
    "        if noise > 0:\n",
    "            vol2 = vol2.data*noise\n",
    "        rmse = np.sqrt(np.mean((vol.data - rec.data)**2))\n",
    "        ssim = structural_similarity(vol.data, rec.data, data_range=rec.data.max() - rec.data.min())\n",
    "        print(noise, rmse, ssim)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 TiltScheme Setup\n",
    "The following section setups a loop to acquire all base tilt scheme angles required in this study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# return all tiltschemes for basic tests\n",
    "def generate_schemes(scheme_selection=None):\n",
    "    schemes = []\n",
    "    labels = []\n",
    "    angles = []\n",
    "    \n",
    "    if scheme_selection is None:\n",
    "        scheme_selection = [0,1,2]\n",
    "    \n",
    "    for set in scheme_selection: \n",
    "        match set:\n",
    "            case 0:\n",
    "                incremental_schemes = [tomobase.tiltschemes.Incremental(-64, 64, 2), \n",
    "                                        tomobase.tiltschemes.Incremental(-64, 64, 4), \n",
    "                                        tomobase.tiltschemes.Incremental(-64, 64, 8), \n",
    "                                        tomobase.tiltschemes.Incremental(-64, 64, 16)]\n",
    "                incremental_angles = [65, 33, 17, 9]\n",
    "                incremental_labels = ['Incremental', 'Incremental', 'Incremental', 'Incremental']\n",
    "                schemes.extend(incremental_schemes)\n",
    "                angles.extend(incremental_angles)\n",
    "                labels.extend(incremental_labels)\n",
    "            case 1:\n",
    "                binary_schemes = [tomobase.tiltschemes.Binary(-64, 64,k=2), \n",
    "                                    tomobase.tiltschemes.Binary(-64, 64,k=2), \n",
    "                                    tomobase.tiltschemes.Binary(-64, 64,k=2),\n",
    "                                    tomobase.tiltschemes.Binary(-64, 64,k=2),\n",
    "                                    tomobase.tiltschemes.Binary(-64, 64,k=4),\n",
    "                                    tomobase.tiltschemes.Binary(-64, 64,k=4),\n",
    "                                    tomobase.tiltschemes.Binary(-64, 64,k=4),\n",
    "                                    tomobase.tiltschemes.Binary(-64, 64,k=4),\n",
    "                                    tomobase.tiltschemes.Binary(-64, 64,k=8),\n",
    "                                    tomobase.tiltschemes.Binary(-64, 64,k=8),\n",
    "                                    tomobase.tiltschemes.Binary(-64, 64,k=8),\n",
    "                                    tomobase.tiltschemes.Binary(-64, 64,k=8), \n",
    "                                    tomobase.tiltschemes.Binary(-64, 64,k=2, isbidirectional=False),\n",
    "                                    tomobase.tiltschemes.Binary(-64, 64,k=2, isbidirectional=False),\n",
    "                                    tomobase.tiltschemes.Binary(-64, 64,k=2, isbidirectional=False),\n",
    "                                    tomobase.tiltschemes.Binary(-64, 64,k=2, isbidirectional=False),\n",
    "                                    tomobase.tiltschemes.Binary(-64, 64,k=4, isbidirectional=False),\n",
    "                                    tomobase.tiltschemes.Binary(-64, 64,k=4, isbidirectional=False),\n",
    "                                    tomobase.tiltschemes.Binary(-64, 64,k=4, isbidirectional=False),\n",
    "                                    tomobase.tiltschemes.Binary(-64, 64,k=4, isbidirectional=False),\n",
    "                                    tomobase.tiltschemes.Binary(-64, 64,k=8, isbidirectional=False),\n",
    "                                    tomobase.tiltschemes.Binary(-64, 64,k=8, isbidirectional=False),\n",
    "                                    tomobase.tiltschemes.Binary(-64, 64,k=8, isbidirectional=False),\n",
    "                                    tomobase.tiltschemes.Binary(-64, 64,k=8, isbidirectional=False)]\n",
    "                binary_angles = [65, 33, 17, 9, 65, 33, 17, 9, 65, 33, 17, 9, 65, 33, 17, 9, 65, 33, 17, 9, 65, 33, 17, 9]\n",
    "                binary_labels = ['Binary 2b', 'Binary 2b', 'Binary 2b', 'Binary 2b', 'Binary 4b', 'Binary 4b', 'Binary 4b', 'Binary 4b', 'Binary 8b', 'Binary 8b', 'Binary 8b', 'Binary 8b', 'Binary 2u', 'Binary 2u', 'Binary 2u', 'Binary 2u', 'Binary 4u', 'Binary 4u', 'Binary 4u', 'Binary 4u', 'Binary 8u', 'Binary 8u', 'Binary 8u', 'Binary 8u']\n",
    "                \n",
    "                schemes.extend(binary_schemes)\n",
    "                angles.extend(binary_angles)\n",
    "                labels.extend(binary_labels)\n",
    "            case 2:\n",
    "                grs_schemes =  [tomobase.tiltschemes.GRS(-64, 64,0),\n",
    "                                tomobase.tiltschemes.GRS(-64, 64,0),\n",
    "                                tomobase.tiltschemes.GRS(-64, 64,0),\n",
    "                                tomobase.tiltschemes.GRS(-64, 64,0)]\n",
    "                grs_angles = [65, 33, 17, 9]\n",
    "                grs_labels = ['GRS', 'GRS', 'GRS', 'GRS']\n",
    "                schemes.extend(grs_schemes)\n",
    "                angles.extend(grs_angles)\n",
    "                labels.extend(grs_labels)\n",
    "    return schemes, angles, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_required_schemes():\n",
    "    schemes = [tomobase.tiltschemes.Incremental(-64, 64, 2), \n",
    "               tomobase.tiltschemes.Binary(-64, 64,k=8), \n",
    "               tomobase.tiltschemes.GRS(-64, 64,0)]\n",
    "    return schemes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "The following section outlines the tests performed in this study\n",
    "\n",
    "Table of Contents\n",
    "\n",
    "[3.1. Display Angles](#31-display-angles) - Displays the angles acquired for novel schemes\n",
    "\n",
    "[3.2. Backlash Corrections](#32-backlash) - Displays Backlash amount and correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 14:53:36,034 - ERROR - hyperspy module not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "65\n",
      "[-64 -62 -60 -58 -56 -54 -52 -50 -48 -46 -44 -42 -40 -38 -36 -34 -32 -30\n",
      " -28 -26 -24 -22 -20 -18 -16 -14 -12 -10  -8  -6  -4  -2   0   2   4   6\n",
      "   8  10  12  14  16  18  20  22  24  26  28  30  32  34  36  38  40  42\n",
      "  44  46  48  50  52  54  56  58  60  62  64]\n",
      "307 307\n",
      "0.07815089299369479 0.8441044439477142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TCraig\\AppData\\Local\\Temp\\ipykernel_24548\\1944227783.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "[-64.   -62.12 -60.24 -58.35 -56.47 -54.59 -52.71 -48.94 -47.06 -45.18\n",
      " -43.29 -41.41 -39.53 -37.65 -33.88 -32.   -30.12 -28.24 -26.35 -24.47\n",
      " -22.59 -18.82 -16.94 -15.06 -13.18 -11.29  -9.41  -7.53  -5.65  -3.76\n",
      "  -1.88   0.     1.88   3.76   5.65   7.53   9.41  11.29  13.18  15.06\n",
      "  16.94  18.82  20.71  22.59  24.47  26.35  28.24  30.12  32.    33.88\n",
      "  35.76  37.65  39.53  41.41  43.29  45.18  47.06  48.94  50.82  52.71\n",
      "  54.59  56.47  58.35  60.24  62.12]\n",
      "307 307\n",
      "0.20124819569885652 0.6526905050471871\n",
      "65\n",
      "[-64.   -62.32 -59.59 -57.91 -55.18 -53.5  -52.46 -50.77 -48.05 -46.37\n",
      " -43.64 -40.92 -39.23 -36.51 -34.82 -33.78 -32.1  -29.37 -27.69 -24.97\n",
      " -23.28 -22.24 -20.56 -17.83 -16.15 -13.42 -10.7   -9.02  -6.29  -4.61\n",
      "  -3.57  -1.88   0.84   2.53   5.25   6.93   7.98   9.66  12.38  14.07\n",
      "  15.11  16.79  19.52  21.2   23.93  25.61  26.65  28.33  31.06  32.74\n",
      "  35.47  38.19  39.88  42.6   44.28  45.33  47.01  49.73  51.42  54.14\n",
      "  55.83  56.87  58.55  61.28  62.96]\n",
      "307 307\n",
      "0.1935430141930343 0.6631634524905304\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tilt Scheme</th>\n",
       "      <th>Angles</th>\n",
       "      <th>Noise</th>\n",
       "      <th>MAE</th>\n",
       "      <th>SSIM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;tomobase.tiltschemes.incremental.Incremental ...</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.078151</td>\n",
       "      <td>0.844104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;tomobase.tiltschemes.binary.Binary object at ...</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.201248</td>\n",
       "      <td>0.652691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;tomobase.tiltschemes.grs.GRS object at 0x0000...</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.193543</td>\n",
       "      <td>0.663163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Tilt Scheme Angles Noise       MAE  \\\n",
       "0  <tomobase.tiltschemes.incremental.Incremental ...     65     0  0.078151   \n",
       "1  <tomobase.tiltschemes.binary.Binary object at ...     65     0  0.201248   \n",
       "2  <tomobase.tiltschemes.grs.GRS object at 0x0000...     65     0  0.193543   \n",
       "\n",
       "       SSIM  \n",
       "0  0.844104  \n",
       "1  0.652691  \n",
       "2  0.663163  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tomobase\n",
    "import numpy as np\n",
    "import tomobase.phantoms\n",
    "import tomobase.processes\n",
    "import tomobase.processes.alignments\n",
    "import tomobase.tiltschemes\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "vol = tomobase.phantoms.nanocage()\n",
    "pd.set_option('display.max_rows', None)\n",
    "import astra\n",
    "print(astra.use_cuda())\n",
    "\n",
    "def get_required_schemes():\n",
    "    schemes = [ tomobase.tiltschemes.Incremental(-64, 64, 2),\n",
    "                tomobase.tiltschemes.Binary(-64, 64,k=8), \n",
    "               tomobase.tiltschemes.GRS(-64, 64,0)]\n",
    "    return schemes\n",
    "\n",
    "schemes = get_required_schemes()\n",
    "df = pd.DataFrame(columns=['Tilt Scheme', 'Angles','Noise', 'MAE', 'SSIM'])\n",
    "for scheme in schemes:\n",
    "    for noise in [0]:\n",
    "        angles = np.array([scheme.get_angle() for i in range(65)])\n",
    "        sinogram = tomobase.processes.project(vol, angles)\n",
    "        print(len(sinogram.angles))\n",
    "        if noise == 0:\n",
    "            sinogram_noisy = sinogram\n",
    "        else:\n",
    "            sinogram_noisy = tomobase.processes.alignments.add_noise(sinogram)\n",
    "        rec = tomobase.processes.reconstruct_weighted_sirt(sinogram_noisy, iterations=100, weighted=False)\n",
    "        #rec = tomobase.processes.reconstruct(sinogram_noisy, 'sirt', iterations=100)\n",
    "        rmse = np.sqrt(np.mean((vol.data-rec.data)**2))\n",
    "        ssim = structural_similarity(vol.data, rec.data, data_range=1.0)\n",
    "        print(rmse, ssim)\n",
    "        new_row = {'Tilt Scheme': scheme, 'Angles': len(angles), 'Noise': noise, 'MAE': rmse, 'SSIM': ssim}\n",
    "        new_row_df = pd.DataFrame([new_row])\n",
    "    \n",
    "        df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "    \n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomobase\n",
    "import numpy as np\n",
    "import tomobase.phantoms\n",
    "import tomobase.processes\n",
    "import tomobase.processes.alignments\n",
    "import tomobase.tiltschemes\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "vol = tomobase.phantoms.nanocage()\n",
    "pd.set_option('display.max_rows', None)\n",
    "import astra\n",
    "print(astra.use_cuda())\n",
    "\n",
    "def get_required_schemes():\n",
    "    schemes = [ tomobase.tiltschemes.Incremental(-64, 64, 2),\n",
    "                tomobase.tiltschemes.Binary(-64, 64,k=8), \n",
    "               tomobase.tiltschemes.GRS(-64, 64,0)]\n",
    "    return schemes\n",
    "\n",
    "schemes = get_required_schemes()\n",
    "df = pd.DataFrame(columns=['Tilt Scheme', 'Angles','Noise', 'MAE', 'SSIM'])\n",
    "for scheme in schemes:\n",
    "    for noise in [0]:\n",
    "        angles = np.array([scheme.get_angle() for i in range(65)])\n",
    "        sinogram = tomobase.processes.project(vol, angles)\n",
    "        print(len(sinogram.angles))\n",
    "        if noise == 0:\n",
    "            sinogram_noisy = sinogram\n",
    "        else:\n",
    "            sinogram_noisy = tomobase.processes.alignments.add_noise(sinogram)\n",
    "        rec = tomobase.processes.reconstruct_weighted_sirt(sinogram_noisy, iterations=100, weighted=False)\n",
    "        #rec = tomobase.processes.reconstruct(sinogram_noisy, 'sirt', iterations=100)\n",
    "        rmse = np.sqrt(np.mean((vol.data-rec.data)**2))\n",
    "        ssim = structural_similarity(vol.data, rec.data, data_range=1.0)\n",
    "        print(rmse, ssim)\n",
    "        new_row = {'Tilt Scheme': scheme, 'Angles': len(angles), 'Noise': noise, 'MAE': rmse, 'SSIM': ssim}\n",
    "        new_row_df = pd.DataFrame([new_row])\n",
    "    \n",
    "        df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "    \n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Display Angles\n",
    "The purpose of this test is just to be able to read off the angles for the binary tiltschemes. Two almost identical scheme sets are presented:\n",
    "\n",
    "1. Unidirectional (u) -  once the highest angle in the set is reached the tiltseries is reverted back to the minimum angle with an offset.\n",
    "2. Bidirectional (b) -  Once the highest angle in the set is reached the tiltseries is offset than angles are collected backwards.\n",
    "\n",
    "Both schemes should have collected the exact same angles in a set of k+1 projections - just in a different order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "schemes, n_angles, labels = generate_schemes([1])\n",
    "coloumns = []\n",
    "\n",
    "for i in range(len(schemes)):\n",
    "    if n_angles[i]==65:\n",
    "        angles = np.array([schemes[i].get_angle() for j in range(n_angles[i])])\n",
    "        coloumns.append(angles)\n",
    "\n",
    "_dict = {\n",
    "    'Binary 2b': coloumns[0],\n",
    "    'Binary 4b': coloumns[1],\n",
    "    'Binary 8b': coloumns[2],\n",
    "    'Binary 2u': coloumns[3],\n",
    "    'Binary 4u': coloumns[4],\n",
    "    'Binary 8u': coloumns[5],\n",
    "}\n",
    "df = pd.DataFrame(_dict)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schemes, n_angles, labels = generate_schemes([0, 1, 2])\n",
    "df = pd.DataFrame(columns=['Tilt Scheme', 'Number of Angles', 'SSIM', 'PSNR', 'MAE'])\n",
    "for i, scheme in enumerate(schemes):\n",
    "    angles = np.array([schemes[i].get_angle() for j in range(n_angles[i])], dtype=np.float64)\n",
    "    wedge_end = np.max(angles)\n",
    "    incremental = tomobase.tiltschemes.Incremental(-64, wedge_end, (wedge_end+64)/(n_angles[i]-1))\n",
    "    angles_inc = np.array([incremental.get_angle() for j in range(n_angles[i])], dtype=np.float64)\n",
    "    \n",
    "    sino = tomobase.processes.project(vol, angles)\n",
    "    rec = tomobase.processes.reconstruct(sino, method=\"sirt\", iterations=100)\n",
    "\n",
    "    ssim  = structural_similarity(vol.data, rec.data, data_range=1.0)\n",
    "    psnr = peak_signal_noise_ratio(vol.data, rec.data, data_range =1.0)\n",
    "    mae = np.mean(np.abs(vol.data - rec.data))\n",
    "    \n",
    "    new_row = {\n",
    "        'Tilt Scheme': labels[i],\n",
    "        'Number of Angles': n_angles[i],\n",
    "        'SSIM': ssim,\n",
    "        'PSNR': psnr,\n",
    "        'MAE': mae\n",
    "    }\n",
    "    \n",
    "    new_row_df = pd.DataFrame([new_row])\n",
    "    df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Uniformity\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "df = pd.DataFrame(columns=['Tilt Scheme', 'Number of Angles', 'SSIM', 'MAE'])\n",
    "scheme = tomobase.tiltschemes.Incremental(-64, 64, 2)\n",
    "angles = np.array([scheme.get_angle() for i in range(65)])\n",
    "\n",
    "sino = tomobase.processes.project(vol, angles)\n",
    "#sino = tomobase.processes.alignments.weight_by_angle(sino)\n",
    "#rec = tomobase.processes.reconstruct_weighted_sirt(sino, method=\"sirt\", iterations=100)\n",
    "rec = tomobase.processes.reconstruct_weighted_sirt(sino, iterations=100)\n",
    "ssim  = structural_similarity(vol.data, rec.data, data_range=1.0)\n",
    "mae = np.mean(np.abs(vol.data - rec.data))\n",
    "new_row = {\n",
    "    'Tilt Scheme': 'GRS',\n",
    "    'Number of Angles': 65,\n",
    "    'SSIM': ssim,\n",
    "    'MAE': mae\n",
    "}\n",
    "\n",
    "new_row_df = pd.DataFrame([new_row])\n",
    "df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Backlash\n",
    "\n",
    "There is an artifact in the microscope gonioometer for bidirectional acquisition schemes. This section outlines its effects on the different tiltschemes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schemes, n_angles, labels = generate_schemes()\n",
    "backlash_value = 0.1\n",
    "\n",
    "banned = [0, 1, 2, 3, 4, 5, 6]\n",
    "\n",
    "df = pd.DataFrame(columns=['Tilt Scheme', 'Number of Angles', 'Backlash Value', 'Cumulated Backlash', 'Correction', 'SSIM without error', 'PSNR without error', 'SSIM with error', 'PSNR with error', 'SSIM corrected', 'PSNR corrected'])\n",
    "for i, scheme in enumerate(schemes):\n",
    "    if i not in banned:\n",
    "        angles = np.array([schemes[i].get_angle() for j in range(n_angles[i])], dtype=np.float64)\n",
    "        sino = tomobase.processes.project(vol, angles)\n",
    "        indices = np.where(np.diff(sino.angles) < 0)[0] + 1\n",
    "        \n",
    "        rec = tomobase.processes.reconstruct(sino, method=\"sirt\", iterations=100)\n",
    "        ssim_without_error = structural_similarity(vol.data, rec.data, data_range=1.0)\n",
    "        psnr_without_error = peak_signal_noise_ratio(vol.data, rec.data, data_range =1.0)\n",
    "        \n",
    "        cumulated_backlash = backlash_value * len(indices)\n",
    "        sino.angles[indices] -= backlash_value\n",
    "        \n",
    "        rec = tomobase.processes.reconstruct(sino, method=\"sirt\", iterations=100)\n",
    "        ssim_with_error = structural_similarity(vol.data, rec.data, data_range=1.0)\n",
    "        psnr_with_error = peak_signal_noise_ratio(vol.data, rec.data, data_range =1.0)\n",
    "         \n",
    "        sino, correction = tomobase.processes.alignments.backlash_correct(sino, extend_return=True)\n",
    "        rec = tomobase.processes.reconstruct(sino, method=\"sirt\", iterations=100)\n",
    "        \n",
    "        ssim_corrected = structural_similarity(vol.data, rec.data, data_range=1.0)\n",
    "        psnr_corrected = peak_signal_noise_ratio(vol.data, rec.data, data_range =1.0)\n",
    "\n",
    "        new_row = {\n",
    "            'Tilt Scheme': labels[i],\n",
    "            'Number of Angles': n_angles[i],\n",
    "            'Backlash Value': backlash_value,\n",
    "            'Cumulated Backlash': cumulated_backlash,\n",
    "            'Correction': correction,\n",
    "            'SSIM without error': ssim_without_error,\n",
    "            'PSNR without error': psnr_without_error,\n",
    "            'SSIM with error': ssim_with_error,\n",
    "            'PSNR with error': psnr_with_error,\n",
    "            'SSIM corrected': ssim_corrected,\n",
    "            'PSNR corrected': psnr_corrected\n",
    "        }\n",
    "\n",
    "        # Convert the new row to a DataFrame\n",
    "        new_row_df = pd.DataFrame([new_row])\n",
    "\n",
    "        # Concatenate the new row with the existing DataFrame\n",
    "        df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "\n",
    "print(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schemes, n_angles, labels = generate_schemes()\n",
    "backlash_value = 0.5\n",
    "\n",
    "banned = [0, 1, 2, 3, 4]\n",
    "\n",
    "df = pd.DataFrame(columns=['Tilt Scheme', 'Number of Angles', 'Backlash Value', 'Cumulated Backlash', 'Correction', 'MAE without error', 'MAE with error', 'MAE corrected'])\n",
    "for i, scheme in enumerate(schemes):\n",
    "    if i not in banned:\n",
    "        angles = np.array([schemes[i].get_angle() for j in range(n_angles[i])], dtype=np.float64)\n",
    "        sino = tomobase.processes.project(vol, angles)\n",
    "        indices = np.where(np.diff(sino.angles) < 0)[0] + 1\n",
    "        \n",
    "        rec = tomobase.processes.reconstruct(sino, method=\"sirt\", iterations=100)\n",
    "        mae_without_error = np.mean(np.abs(vol.data - rec.data))\n",
    "        \n",
    "        cumulated_backlash = backlash_value * len(indices)\n",
    "        sino.angles[indices] -= backlash_value\n",
    "        \n",
    "        if len(indices) > 0:\n",
    "            rec = tomobase.processes.reconstruct(sino, method=\"sirt\", iterations=100)\n",
    "            mae_with_error = np.mean(np.abs(vol.data - rec.data))\n",
    "            \n",
    "            sino, correction = tomobase.processes.alignments.backlash_correct(sino, extend_return=True)\n",
    "            rec = tomobase.processes.reconstruct(sino, method=\"sirt\", iterations=100)\n",
    "            mae_corrected = np.mean(np.abs(vol.data - rec.data))\n",
    "        else:\n",
    "            mae_with_error = mae_without_error\n",
    "            mae_corrected = mae_without_error\n",
    "            correction = 0\n",
    "\n",
    "        new_row = {\n",
    "            'Tilt Scheme': labels[i],\n",
    "            'Number of Angles': n_angles[i],\n",
    "            'Backlash Value': backlash_value,\n",
    "            'Cumulated Backlash': cumulated_backlash,\n",
    "            'Correction': correction,\n",
    "            'MAE without error': mae_without_error,\n",
    "            'MAE with error': mae_with_error,\n",
    "            'MAE corrected': mae_corrected\n",
    "        }\n",
    "\n",
    "        # Convert the new row to a DataFrame\n",
    "        new_row_df = pd.DataFrame([new_row])\n",
    "\n",
    "        # Concatenate the new row with the existing DataFrame\n",
    "        df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schemes, n_angles, labels = generate_schemes()\n",
    "backlash_value = 0.5\n",
    "\n",
    "banned = []\n",
    "\n",
    "df = pd.DataFrame(columns=['Tilt Scheme', 'Number of Angles', 'Backlash Value', 'Cumulated Backlash'])\n",
    "for i, scheme in enumerate(schemes):\n",
    "    if i not in banned:\n",
    "        angles = np.array([schemes[i].get_angle() for j in range(n_angles[i])], dtype=np.float64)\n",
    "        sino = tomobase.processes.project(vol, angles)\n",
    "        indices = np.where(np.diff(sino.angles) < 0)[0] + 1\n",
    "        \n",
    "        cumulated_backlash = backlash_value * len(indices)\n",
    "        sino.angles[indices] -= backlash_value\n",
    "\n",
    "        new_row = {\n",
    "            'Tilt Scheme': labels[i],\n",
    "            'Number of Angles': n_angles[i],\n",
    "            'Backlash Value': backlash_value,\n",
    "            'Cumulated Backlash': cumulated_backlash,\n",
    "        }\n",
    "\n",
    "        # Convert the new row to a DataFrame\n",
    "        new_row_df = pd.DataFrame([new_row])\n",
    "\n",
    "        # Concatenate the new row with the existing DataFrame\n",
    "        df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Wedge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schemes, n_angles, labels = generate_schemes()\n",
    "\n",
    "banned = []\n",
    "\n",
    "df = pd.DataFrame(columns=['Tilt Scheme', 'Number of Angles', 'Missing Wedge'])\n",
    "for i, scheme in enumerate(schemes):\n",
    "    if i not in banned:\n",
    "        angles = np.array([schemes[i].get_angle() for j in range(n_angles[i])], dtype=np.float64)\n",
    "        missing_wedge = 180 - (np.max(angles) - np.min(angles))\n",
    "\n",
    "\n",
    "        new_row = {\n",
    "            'Tilt Scheme': labels[i],\n",
    "            'Number of Angles': n_angles[i],\n",
    "            'Missing Wedge': missing_wedge,\n",
    "        }\n",
    "\n",
    "        # Convert the new row to a DataFrame\n",
    "        new_row_df = pd.DataFrame([new_row])\n",
    "\n",
    "        # Concatenate the new row with the existing DataFrame\n",
    "        df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schemes, n_angles, labels = generate_schemes([1,2])\n",
    "df = pd.DataFrame(columns=['Tilt Scheme', 'Number of Angles', 'SSIM', 'PSNR', 'MAE'])\n",
    "for i, scheme in enumerate(schemes):\n",
    "    angles = np.array([schemes[i].get_angle() for j in range(n_angles[i])], dtype=np.float64)\n",
    "    wedge_end = np.max(angles)\n",
    "    incremental = tomobase.tiltschemes.Incremental(-64, wedge_end, (wedge_end+64)/(n_angles[i]-1))\n",
    "    angles_inc = np.array([incremental.get_angle() for j in range(n_angles[i])], dtype=np.float64)\n",
    "    \n",
    "    sino = tomobase.processes.project(vol, angles_inc)\n",
    "    rec = tomobase.processes.reconstruct(sino, method=\"sirt\", iterations=100)\n",
    "\n",
    "    ssim  = structural_similarity(vol.data, rec.data, data_range=1.0)\n",
    "    psnr = peak_signal_noise_ratio(vol.data, rec.data, data_range =1.0)\n",
    "    mae = np.mean(np.abs(vol.data - rec.data))\n",
    "    \n",
    "    new_row = {\n",
    "        'Tilt Scheme': labels[i],\n",
    "        'Number of Angles': n_angles[i],\n",
    "        'SSIM': ssim,\n",
    "        'PSNR': psnr,\n",
    "        'MAE': mae\n",
    "    }\n",
    "    \n",
    "    new_row_df = pd.DataFrame([new_row])\n",
    "    df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Translational Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schemes, n_angles, labels = generate_schemes()\n",
    "banned = []\n",
    "df = pd.DataFrame(columns=['Tilt Scheme', 'Number of Angles', 'Alignment Error', 'Measurement Error'])\n",
    "for i, scheme in enumerate(schemes):\n",
    "    if i not in banned:\n",
    "        angles = np.array([schemes[i].get_angle() for j in range(n_angles[i])], dtype=np.float64)\n",
    "        experiment_offset =[]\n",
    "        for j in range(10):\n",
    "            ts = tomobase.processes.project(vol, angles)\n",
    "            ts = tomobase.processes.alignments.pad_sinogram(ts, 1024, 1024, inplace=False)\n",
    "\n",
    "            sorted_indices = np.argsort(ts.angles)\n",
    "            ts.angles = ts.angles[sorted_indices]\n",
    "            ts.data = ts.data[:, :, sorted_indices]\n",
    "            ts, shifts = tomobase.processes.alignments.translational_misalignment(ts, 0.2, 0.2, extend_return=True)\n",
    "            ts, shifts_corrected = tomobase.processes.alignments.align_sinogram_xcorr(ts, extend_return=True)   \n",
    "        \n",
    "            offsets = (shifts_corrected + shifts)%1024\n",
    "            offsets[offsets>512] = np.abs(offsets[offsets>512] - 1024)\n",
    "            experiment_offset.append(np.mean(offsets))\n",
    "        \n",
    "        offsets = np.mean(experiment_offset)\n",
    "        experiment_offset = np.array(experiment_offset)\n",
    "        new_row = {\n",
    "            'Tilt Scheme': labels[i],\n",
    "            'Number of Angles': n_angles[i],\n",
    "            'Alignment Error': offsets,\n",
    "            'Measurement Error': (np.max(experiment_offset) - np.min(experiment_offset))/2\n",
    "        }\n",
    "\n",
    "        # Convert the new row to a DataFrame\n",
    "        new_row_df = pd.DataFrame([new_row])\n",
    "\n",
    "        # Concatenate the new row with the existing DataFrame\n",
    "        df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schemes, n_angles, labels = generate_schemes()\n",
    "banned = []\n",
    "df = pd.DataFrame(columns=['Tilt Scheme', 'Number of Angles', 'Alignment Error', 'Measurement Error', 'SSIM', 'SSIM Error','PSNR','PSNR Error', 'MAE', 'MAE Error'])\n",
    "max_value = 0\n",
    "min_value = 100000000\n",
    "\n",
    "max_ssim = 0\n",
    "min_ssim = 1000000000\n",
    "\n",
    "max_psnr = 0\n",
    "min_psnr = 1000000000\n",
    "\n",
    "max_mae = 0\n",
    "min_mae = 1000000000\n",
    "\n",
    "for i, scheme in enumerate(schemes):\n",
    "    if i not in banned:\n",
    "        angles = np.array([schemes[i].get_angle() for j in range(n_angles[i])], dtype=np.float64)\n",
    "        experiment_offset =[]\n",
    "        ssims = []\n",
    "        psnrs = []\n",
    "        maes = []\n",
    "        for j in range(10):\n",
    "            ts = tomobase.processes.project(vol, angles)\n",
    "            ts = tomobase.processes.alignments.pad_sinogram(ts, 1024, 1024, inplace=False)\n",
    "\n",
    "            sorted_indices = np.argsort(ts.angles)\n",
    "            ts.angles = ts.angles[sorted_indices]\n",
    "            ts.data = ts.data[:, :, sorted_indices]\n",
    "            ts, shifts = tomobase.processes.alignments.translational_misalignment(ts, 0.2, 0.2, extend_return=True)\n",
    "            ts, shifts_corrected = tomobase.processes.alignments.align_sinogram_xcorr(ts, extend_return=True)   \n",
    "        \n",
    "            offsets = (shifts_corrected + shifts)%1024\n",
    "            offsets[offsets>512] = np.abs(offsets[offsets>512] - 1024)\n",
    "            experiment_offset.append(np.mean(offsets))\n",
    "            if np.max(offsets)>max_value:\n",
    "                max_value = np.max(offsets)\n",
    "            if np.min(offsets)<min_value:\n",
    "                min_value = np.min(offsets)\n",
    "            \n",
    "            # Crop the sinogram to 307x307\n",
    "            crop_height, crop_width = (307,307)\n",
    "            height, width = ts.data.shape[:2]\n",
    "\n",
    "\n",
    "            start_y = (height - crop_height) // 2\n",
    "            end_y = start_y + crop_height\n",
    "            start_x = (width - crop_width) // 2\n",
    "            end_x = start_x + crop_width\n",
    "\n",
    "\n",
    "            ts.data = ts.data[start_y:end_y, start_x:end_x, :]\n",
    "            rec = tomobase.processes.reconstruct(ts, method=\"sirt\", iterations=100)\n",
    "            ssims.append(structural_similarity(vol.data, rec.data, data_range=1.0))\n",
    "            psnrs.append(peak_signal_noise_ratio(vol.data, rec.data, data_range =1.0))\n",
    "            maes.append(np.mean(np.abs(vol.data - rec.data)))\n",
    "                        \n",
    "            if np.max(ssims)>max_ssim:\n",
    "                max_ssim = np.max(ssims)\n",
    "            if np.min(ssims)<min_ssim:\n",
    "                min_ssim = np.min(ssims)\n",
    "            if np.max(psnrs)>max_psnr:\n",
    "                max_psnr = np.max(psnrs)\n",
    "            if np.min(psnrs)<min_psnr:\n",
    "                min_psnr = np.min(psnrs)\n",
    "            if np.max(maes)>max_mae:\n",
    "                max_mae = np.max(maes)\n",
    "            if np.min(maes)<min_mae:\n",
    "                min_mae = np.min(maes)\n",
    "            \n",
    "        offsets = np.mean(experiment_offset)\n",
    "        experiment_offset = np.array(experiment_offset)\n",
    "        new_row = {\n",
    "            'Tilt Scheme': labels[i],\n",
    "            'Number of Angles': n_angles[i],\n",
    "            'Alignment Error': offsets,\n",
    "            'Measurement Error': (max_value - min_value)/2,\n",
    "            'SSIM': np.mean(ssims),\n",
    "            'SSIM Error': (max_ssim - min_ssim)/2,\n",
    "            'PSNR': np.mean(psnrs),\n",
    "            'PSNR Error': (max_psnr - min_psnr)/2,\n",
    "            'MAE': np.mean(maes),\n",
    "            'MAE Error': (max_mae - min_mae)/2\n",
    "        }\n",
    "\n",
    "        # Convert the new row to a DataFrame\n",
    "        new_row_df = pd.DataFrame([new_row])\n",
    "\n",
    "        # Concatenate the new row with the existing DataFrame\n",
    "        df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[-64 -62 -60 -58 -56 -54 -52 -50 -48 -46 -44 -42 -40 -38 -36 -34 -32 -30\n",
      " -28 -26 -24 -22 -20 -18 -16 -14 -12 -10  -8  -6  -4  -2   0   2   4   6\n",
      "   8  10  12  14  16  18  20  22  24  26  28  30  32  34  36  38  40  42\n",
      "  44  46  48  50  52  54  56  58  60  62  64]\n",
      "307 307\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m sinogram \u001b[38;5;241m=\u001b[39m tomobase\u001b[38;5;241m.\u001b[39mprocesses\u001b[38;5;241m.\u001b[39mproject(vol, angles)\n\u001b[0;32m     25\u001b[0m sinogram_noisy \u001b[38;5;241m=\u001b[39m sinogram\n\u001b[1;32m---> 26\u001b[0m rec \u001b[38;5;241m=\u001b[39m \u001b[43mtomobase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocesses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreconstruct_weighted_sirt\u001b[49m\u001b[43m(\u001b[49m\u001b[43msinogram_noisy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweighted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#rec = tomobase.processes.reconstruct(sinogram_noisy, 'sirt', iterations=100)\u001b[39;00m\n\u001b[0;32m     28\u001b[0m rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39mmean((vol\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m-\u001b[39mrec\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[1;32md:\\code\\github\\timedependenttomography\\submodules\\tomobase\\tomobase\\processes\\reconstruct.py:97\u001b[0m, in \u001b[0;36mreconstruct_weighted_sirt\u001b[1;34m(sino, iterations, use_gpu, weighted)\u001b[0m\n\u001b[0;32m     95\u001b[0m D \u001b[38;5;241m=\u001b[39m R\u001b[38;5;241m*\u001b[39m(B \u001b[38;5;241m-\u001b[39m A)\n\u001b[0;32m     96\u001b[0m vol[i, :, :] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m C\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mreshape(W\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m*\u001b[39mD,(d,d))\n\u001b[1;32m---> 97\u001b[0m vol[i, :, :] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(np\u001b[38;5;241m.\u001b[39mminimum(vol[i, :, :], \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m), (d, d))\n\u001b[0;32m     98\u001b[0m vol[i, :, :] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(np\u001b[38;5;241m.\u001b[39mmaximum(vol[i, :, :], \u001b[38;5;241m0\u001b[39m), (d, d))\n\u001b[0;32m     99\u001b[0m vol[i, :, :] \u001b[38;5;241m=\u001b[39m vol[i, :, :] \u001b[38;5;241m*\u001b[39m (default_mask \u001b[38;5;241m&\u001b[39m mask[i, :, :])\n",
      "File \u001b[1;32mc:\\Users\\TCraig\\AppData\\Local\\miniconda3\\envs\\total-env\\Lib\\site-packages\\numpy\\core\\_methods.py:41\u001b[0m, in \u001b[0;36m_amax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     40\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_maximum(a, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out, keepdims, initial, where)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tomobase\n",
    "import numpy as np\n",
    "import tomobase.phantoms\n",
    "import tomobase.processes\n",
    "import tomobase.processes.alignments\n",
    "import tomobase.tiltschemes\n",
    "import pandas as pd\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "vol = tomobase.phantoms.nanocage()\n",
    "pd.set_option('display.max_rows', None)\n",
    "import astra\n",
    "print(astra.use_cuda())\n",
    "\n",
    "def get_required_schemes():\n",
    "    schemes = [ tomobase.tiltschemes.Incremental(-64, 64, 2),\n",
    "                tomobase.tiltschemes.Binary(-64, 64,k=8), \n",
    "               tomobase.tiltschemes.GRS(-64, 64,0)]\n",
    "    return schemes\n",
    "\n",
    "schemes = get_required_schemes()\n",
    "for scheme in schemes:\n",
    "    angles = np.array([scheme.get_angle() for i in range(65)])\n",
    "    sinogram = tomobase.processes.project(vol, angles)\n",
    "    sinogram_noisy = sinogram\n",
    "    rec = tomobase.processes.reconstruct_weighted_sirt(sinogram_noisy, iterations=100, weighted=False)\n",
    "    #rec = tomobase.processes.reconstruct(sinogram_noisy, 'sirt', iterations=100)\n",
    "    rmse = np.sqrt(np.mean((vol.data-rec.data)**2))\n",
    "    ssim = structural_similarity(vol.data, rec.data, data_range=1.0)\n",
    "    print(rmse, ssim)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "total-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
